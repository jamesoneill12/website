<!DOCTYPE html>
<html lang="en">
<head>
  <title>Horizontal Learning</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <link rel="stylesheet" href="style/research.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
</head>

<body>

  <div class="header">
    <h2>Research Interests<</h2>
  </div>

<div class="topnav">
  <a href="research/capsule_networks.html">Capsule Networks</a>
  <a href="research/adversarial_networks.html">Adversarial Networks</a>
  <a href="research/reinforcement_learning.html">Reinforcement Learning</a>
  <a href="research/graph_modelling.html">Graph Structure Modelling</a>
  <a href="research/horizontal_learning.html">Transfer Learning</a>
  <a href="research/search.html">Search</a>
  <a href="research/other.html" style="float:right">Other</a>
  
</div>

  <h2>Transfer, Multi-task &amp; Domain Adaptation Learning</h2>
  More often than not in machine learning (ML), we train models from scratch and do not take advantage of data and learnt models for similar and related tasks. More recently, the goal of consolidating knowledge across tasks has become a very active area of research (transfer learning or meta-learning). I refer to this type of learning as ‘horizontal learning’ (learning what to transfer across tasks) as opposed to ‘vertical learning’ (task specific learning).

  An interesting recent paper by Andrychowicz et al. (andrychowicz2016learning) view transfer learning as an optimization problem, proposing optimization as a learning problem and comparing against typical optimizations such as ADAM, Nesterov Accelerated Gradient (NAG) and RMSProp. This allows the optimizers to be identified that are well suited to particular types of functions.

  We witnessed a remarkable degree of transfer, with for example theLSTM optimizer trained on 12,288 parameter neural art tasks being able to generalize to tasks with 49,152 parameters, different styles, and different content images all at the same time. We observedsimilar impressive results when transferring to different architectures in the MNIST task.The results on the CIFAR image labeling task show that the LSTM optimizers outperform hand-engineered optimizers when transferring to datasets drawn from the same data distribution.
  <h2>One/Few Shot Learning</h2>
  Humans often learn from only few examples, leveraging knowledge from what they know about related concepts in the world to help guide their understanding for a new concept. I am interested in tasks where little is known about a given class or at least classes are highly imbalanced, a ubiquity in ML.

  One shot imitation learning is a recent approach presented by Duan et al. ~\cite{duan2017one} to learn from little number of examples using an imitation network

  Specifically, we consider the setting where there is a very large (maybe infinite) set of tasks, and each task has many instantiations. For example,a task could be to stack all blocks on a table in to a single tower, another task could be to place all blocks on a table into two-block towers, etc. In each case, different instances of the task would consist of different sets of blocks with different initial states. At training time, our algorithm is presented with pairs of demonstrations for a sub-set of all tasks. A neural net is trained that takes as input one demonstration and the current state(which initially is the initial state of the other demonstration of the pair), and outputs an action with the goal that the resulting sequence of states and actions matches as closely as possible with the second demonstration. At test time, a demonstration of a single instance of a new task is presented, and the neural net is expected to perform well on new instances of this new task. Our experiments show that the use of soft attention al-lows the model to generalize to conditions and tasks unseen in the training data. We anticipate that by training this model on a much greater variety of tasks and settings, we will obtain a general system that can turn any demonstrations into robust policies that can accomplish an over-whelming variety of tasks

</body>


</html>
